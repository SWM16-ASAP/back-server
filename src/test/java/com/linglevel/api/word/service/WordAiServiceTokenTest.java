package com.linglevel.api.word.service;

import com.fasterxml.jackson.databind.ObjectMapper;
import com.linglevel.api.word.dto.WordAnalysisResult;
import lombok.extern.slf4j.Slf4j;
import org.junit.jupiter.api.Disabled;
import org.junit.jupiter.api.DisplayName;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.test.context.ActiveProfiles;

import java.util.List;

import static org.assertj.core.api.Assertions.assertThat;

/**
 * WordAiService í† í° í¬ê¸° ë° ë¹„ìš© ì¸¡ì • í…ŒìŠ¤íŠ¸
 *
 * ì£¼ì˜:
 * - ì‹¤ì œ AI APIë¥¼ í˜¸ì¶œí•˜ë¯€ë¡œ ë¹„ìš©ì´ ë°œìƒí•©ë‹ˆë‹¤
 * - ê¸°ë³¸ì ìœ¼ë¡œ @Disabledë¡œ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤
 * - í† í° í¬ê¸°ë¥¼ í™•ì¸í•˜ê³  ì‹¶ì„ ë•Œë§Œ ì£¼ì„ì„ ì œê±°í•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”
 *
 * ì‹¤í–‰ ë°©ë²•:
 * 1. @Disabled ì£¼ì„ ì œê±°
 * 2. ./gradlew test --tests WordAiServiceTokenTest
 *
 * ì°¸ê³ :
 * - WordAiServiceì—ì„œ ìë™ìœ¼ë¡œ í† í° ì‚¬ìš©ëŸ‰ê³¼ ë¹„ìš©ì„ ë¡œê¹…í•©ë‹ˆë‹¤
 * - ì…ë ¥: $0.00017 per 1K tokens, ì¶œë ¥: $0.000085 per 1K tokens
 * - í™˜ìœ¨: 1 USD = 1430 KRW
 */
@SpringBootTest
@ActiveProfiles("local")
@Slf4j
@Disabled("ì‹¤ì œ AI APIë¥¼ í˜¸ì¶œí•˜ë¯€ë¡œ í•„ìš”í•  ë•Œë§Œ ì‹¤í–‰ (ë¹„ìš© ë°œìƒ)")
class WordAiServiceTokenTest {

    @Autowired
    private WordAiService wordAiService;

    @Autowired
    private ObjectMapper objectMapper;

    @Test
    @DisplayName("Homograph ë‹¨ì–´ 'saw' ì‘ë‹µ í† í° í¬ê¸° ì¸¡ì •")
    void measureTokenSize_saw() throws Exception {
        // given
        String word = "saw";
        String targetLanguage = "KO";

        // when
        List<WordAnalysisResult> results = wordAiService.analyzeWord(word, targetLanguage);

        // then
        assertThat(results).isNotEmpty();

        // JSONìœ¼ë¡œ ì§ë ¬í™”
        String jsonResponse = objectMapper.writerWithDefaultPrettyPrinter()
                .writeValueAsString(results);

        // í¬ê¸° ì¸¡ì •
        int characterCount = jsonResponse.length();
        int estimatedTokens = characterCount / 4; // ëŒ€ëµì ì¸ í† í° ìˆ˜ (1 í† í° â‰ˆ 4ì)

        // ë¡œê·¸ ì¶œë ¥
        log.info("\n" + "=".repeat(100));
        log.info("ë‹¨ì–´: {}", word);
        log.info("ê²°ê³¼ ê°œìˆ˜: {}", results.size());
        log.info("=".repeat(100));
        log.info("JSON ì‘ë‹µ:\n{}", jsonResponse);
        log.info("=".repeat(100));
        log.info("ğŸ“Š ì‘ë‹µ í¬ê¸° í†µê³„:");
        log.info("  - ë¬¸ì ìˆ˜: {} characters", characterCount);
        log.info("  - ì˜ˆìƒ í† í° ìˆ˜: ~{} tokens (ë¬¸ììˆ˜ / 4)", estimatedTokens);
        log.info("  - ë°”ì´íŠ¸ í¬ê¸°: {} bytes", jsonResponse.getBytes().length);
        log.info("=".repeat(100));

        // í˜„ì¬ max-tokens ì„¤ì •ê³¼ ë¹„êµ
        int currentMaxTokens = 2000;
        if (estimatedTokens > currentMaxTokens) {
            log.warn("âš ï¸  ì˜ˆìƒ í† í° ìˆ˜({})ê°€ í˜„ì¬ ì„¤ì •({}tokens)ì„ ì´ˆê³¼í•©ë‹ˆë‹¤!", estimatedTokens, currentMaxTokens);
        } else {
            double usagePercentage = (double) estimatedTokens / currentMaxTokens * 100;
            log.info("âœ… í˜„ì¬ max-tokens ì„¤ì •({})ìœ¼ë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤ (ì‚¬ìš©ë¥ : {:.1f}%)", currentMaxTokens, usagePercentage);
        }
    }

    @Test
    @DisplayName("Homograph ë‹¨ì–´ 'left' ì‘ë‹µ í† í° í¬ê¸° ì¸¡ì •")
    void measureTokenSize_left() throws Exception {
        // given
        String word = "left";
        String targetLanguage = "KO";

        // when
        List<WordAnalysisResult> results = wordAiService.analyzeWord(word, targetLanguage);

        // then
        assertThat(results).isNotEmpty();

        String jsonResponse = objectMapper.writerWithDefaultPrettyPrinter()
                .writeValueAsString(results);

        int characterCount = jsonResponse.length();
        int estimatedTokens = characterCount / 4;

        log.info("\n" + "=".repeat(100));
        log.info("ë‹¨ì–´: {}", word);
        log.info("ê²°ê³¼ ê°œìˆ˜: {}", results.size());
        log.info("=".repeat(100));
        log.info("JSON ì‘ë‹µ:\n{}", jsonResponse);
        log.info("=".repeat(100));
        log.info("ğŸ“Š ì‘ë‹µ í¬ê¸° í†µê³„:");
        log.info("  - ë¬¸ì ìˆ˜: {} characters", characterCount);
        log.info("  - ì˜ˆìƒ í† í° ìˆ˜: ~{} tokens", estimatedTokens);
        log.info("  - ë°”ì´íŠ¸ í¬ê¸°: {} bytes", jsonResponse.getBytes().length);
        log.info("=".repeat(100));

        int currentMaxTokens = 2000;
        if (estimatedTokens > currentMaxTokens) {
            log.warn("âš ï¸  ì˜ˆìƒ í† í° ìˆ˜({})ê°€ í˜„ì¬ ì„¤ì •({}tokens)ì„ ì´ˆê³¼í•©ë‹ˆë‹¤!", estimatedTokens, currentMaxTokens);
        } else {
            double usagePercentage = (double) estimatedTokens / currentMaxTokens * 100;
            log.info("âœ… í˜„ì¬ max-tokens ì„¤ì •({})ìœ¼ë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤ (ì‚¬ìš©ë¥ : {:.1f}%)", currentMaxTokens, usagePercentage);
        }
    }

    @Test
    @DisplayName("Homograph ë‹¨ì–´ 'rose' ì‘ë‹µ í† í° í¬ê¸° ì¸¡ì •")
    void measureTokenSize_rose() throws Exception {
        // given
        String word = "rose";
        String targetLanguage = "KO";

        // when
        List<WordAnalysisResult> results = wordAiService.analyzeWord(word, targetLanguage);

        // then
        assertThat(results).isNotEmpty();

        String jsonResponse = objectMapper.writerWithDefaultPrettyPrinter()
                .writeValueAsString(results);

        int characterCount = jsonResponse.length();
        int estimatedTokens = characterCount / 4;

        log.info("\n" + "=".repeat(100));
        log.info("ë‹¨ì–´: {}", word);
        log.info("ê²°ê³¼ ê°œìˆ˜: {}", results.size());
        log.info("=".repeat(100));
        log.info("JSON ì‘ë‹µ:\n{}", jsonResponse);
        log.info("=".repeat(100));
        log.info("ğŸ“Š ì‘ë‹µ í¬ê¸° í†µê³„:");
        log.info("  - ë¬¸ì ìˆ˜: {} characters", characterCount);
        log.info("  - ì˜ˆìƒ í† í° ìˆ˜: ~{} tokens", estimatedTokens);
        log.info("  - ë°”ì´íŠ¸ í¬ê¸°: {} bytes", jsonResponse.getBytes().length);
        log.info("=".repeat(100));

        int currentMaxTokens = 2000;
        if (estimatedTokens > currentMaxTokens) {
            log.warn("âš ï¸  ì˜ˆìƒ í† í° ìˆ˜({})ê°€ í˜„ì¬ ì„¤ì •({}tokens)ì„ ì´ˆê³¼í•©ë‹ˆë‹¤!", estimatedTokens, currentMaxTokens);
        } else {
            double usagePercentage = (double) estimatedTokens / currentMaxTokens * 100;
            log.info("âœ… í˜„ì¬ max-tokens ì„¤ì •({})ìœ¼ë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤ (ì‚¬ìš©ë¥ : {:.1f}%)", currentMaxTokens, usagePercentage);
        }
    }

    @Test
    @DisplayName("ì¼ë°˜ ë‹¨ì–´ 'run' ì‘ë‹µ í† í° í¬ê¸° ì¸¡ì • (ë¹„êµìš©)")
    void measureTokenSize_run() throws Exception {
        // given
        String word = "run";
        String targetLanguage = "KO";

        // when
        List<WordAnalysisResult> results = wordAiService.analyzeWord(word, targetLanguage);

        // then
        assertThat(results).isNotEmpty();

        String jsonResponse = objectMapper.writerWithDefaultPrettyPrinter()
                .writeValueAsString(results);

        int characterCount = jsonResponse.length();
        int estimatedTokens = characterCount / 4;

        log.info("\n" + "=".repeat(100));
        log.info("ë‹¨ì–´: {} (ì¼ë°˜ ë‹¨ì–´ - ë¹„êµìš©)", word);
        log.info("ê²°ê³¼ ê°œìˆ˜: {}", results.size());
        log.info("=".repeat(100));
        log.info("JSON ì‘ë‹µ:\n{}", jsonResponse);
        log.info("=".repeat(100));
        log.info("ğŸ“Š ì‘ë‹µ í¬ê¸° í†µê³„:");
        log.info("  - ë¬¸ì ìˆ˜: {} characters", characterCount);
        log.info("  - ì˜ˆìƒ í† í° ìˆ˜: ~{} tokens", estimatedTokens);
        log.info("  - ë°”ì´íŠ¸ í¬ê¸°: {} bytes", jsonResponse.getBytes().length);
        log.info("=".repeat(100));

        int currentMaxTokens = 2000;
        if (estimatedTokens > currentMaxTokens) {
            log.warn("âš ï¸  ì˜ˆìƒ í† í° ìˆ˜({})ê°€ í˜„ì¬ ì„¤ì •({}tokens)ì„ ì´ˆê³¼í•©ë‹ˆë‹¤!", estimatedTokens, currentMaxTokens);
        } else {
            double usagePercentage = (double) estimatedTokens / currentMaxTokens * 100;
            log.info("âœ… í˜„ì¬ max-tokens ì„¤ì •({})ìœ¼ë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤ (ì‚¬ìš©ë¥ : {:.1f}%)", currentMaxTokens, usagePercentage);
        }
    }
}
